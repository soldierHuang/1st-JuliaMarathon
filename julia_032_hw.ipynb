{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.4.1",
      "language": "julia",
      "name": "julia-1.4"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.1"
    },
    "colab": {
      "name": "julia_032_hw.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2F_j8Ah5mHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "d6d05d6e-d277-4a7f-9ff4-e68b72278eda"
      },
      "source": [
        "%%shell\n",
        "if ! command -v julia 3>&1 > /dev/null\n",
        "then\n",
        "    wget 'https://julialang-s3.julialang.org/bin/linux/x64/1.4/julia-1.4.1-linux-x86_64.tar.gz' -O julia.tar.gz\n",
        "    tar -x -f julia.tar.gz -C /usr/local --strip-components 1\n",
        "    rm julia.tar.gz\n",
        "fi\n",
        "    julia -e '\\\n",
        "        using Pkg                                                          ;\\\n",
        "        Pkg.update()                                                       ;\\\n",
        "        Pkg.add(\"IJulia\")                                                  ;\\\n",
        "        Pkg.add(\"Flux\")                                                    ;\\\n",
        "        Pkg.add(\"MLDatasets\")                                              ;\\\n",
        "        Pkg.add(\"Statistics\")                                              ;\\\n",
        "        Pkg.update()                                                       ;\\\n",
        "        Pkg.precompile()                                                   ;\\'\n",
        "echo 'Done'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Updating registry at `~/.julia/registries/General`\n",
            "   Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
            "\u001b[2K\u001b[?25h   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "  Resolving package versions...\n",
            "   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "  Resolving package versions...\n",
            "   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "  Resolving package versions...\n",
            "   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "  Resolving package versions...\n",
            "   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "   Updating registry at `~/.julia/registries/General`\n",
            "   Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
            "\u001b[?25l\u001b[2K\u001b[?25h   Updating `~/.julia/environments/v1.4/Project.toml`\n",
            " [no changes]\n",
            "   Updating `~/.julia/environments/v1.4/Manifest.toml`\n",
            " [no changes]\n",
            "Precompiling project...\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfOMsexE5W3H",
        "colab_type": "text"
      },
      "source": [
        "# Julia 深度學習：類神經網路模型簡介\n",
        "\n",
        "## 作業 032：訓練 MLP 學習門牌號碼資料集\n",
        "\n",
        "訓練一個 MLP 模型來學習門牌號碼資料集。\n",
        "\n",
        "注意：MLP 模型的能力有限，可能會導致訓練起來效果不佳。\n",
        "\n",
        "注意：近期 Flux 正在持續更新，請確保您的 Julia 在 v1.3 版以上，以及 Flux 在 v0.10.4 以上或是最新版。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPFKF9FC5W3L",
        "colab_type": "text"
      },
      "source": [
        "## 讀取資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4bHcXWi5W3M",
        "colab_type": "text"
      },
      "source": [
        "呼叫 SVHN2 資料集的過程中，會先去檢查以前是否有下載過，如果是第一次下載，過程中會詢問是否下載資料集，請回答 `y`。整個資料集的大小約為 1.6 GB，下載時間可能會稍久，請耐心等候。\n",
        "\n",
        "\n",
        "    using Flux\n",
        "    using Flux.Data: DataLoader\n",
        "    using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
        "    using MLDatasets\n",
        "    using Statistics\n",
        "\n",
        "    train_X, train_y = SVHN2.traindata(Float32)\n",
        "    test_X,  test_y  = SVHN2.testdata(Float32)\n",
        "\n",
        "    train_X = Flux.flatten(train_X)\n",
        "    test_X = Flux.flatten(test_X)\n",
        "    train_y = onehotbatch(train_y, 1:10)\n",
        "    test_y = onehotbatch(test_y, 1:10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riIKxFka7vML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "45e57770-20e8-4e4f-ba23-7dadd029d98d"
      },
      "source": [
        "!julia -e '\\\n",
        "using Flux                                                                                        ;\\\n",
        "using Flux.Data: DataLoader                                                                       ;\\\n",
        "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy                            ;\\\n",
        "using MLDatasets                                                                                  ;\\\n",
        "using Statistics                                                                                  ;\\\n",
        "train_X, train_y = SVHN2.traindata(Float32)                                                       ;\\\n",
        "test_X,  test_y  = SVHN2.testdata(Float32)                                                        ;\\\n",
        "train_X = Flux.flatten(train_X)                                                                   ;\\\n",
        "test_X = Flux.flatten(test_X)                                                                     ;\\\n",
        "train_y = onehotbatch(train_y, 1:10)                                                              ;\\\n",
        "test_y = onehotbatch(test_y, 1:10)                                                                ;\\\n",
        "batchsize = 1024                                                                                  ;\\\n",
        "train = DataLoader(train_X, train_y, batchsize=batchsize, shuffle=true)                           ;\\\n",
        "test = DataLoader(test_X, test_y, batchsize=batchsize)                                            ;\\\n",
        "model = Chain( Dense(3072, 512, relu), Dense(512, 64, relu),  Dense(64, 10),  softmax )           ;\\\n",
        "loss(x, y) = logitcrossentropy(model(x), y)                                                       ;\\\n",
        "function test_loss()                                                                              ;\\\n",
        "    l = 0f0                                                                                       ;\\\n",
        "    for (x, y) in test                                                                            ;\\\n",
        "        l += loss(x, y)                                                                           ;\\\n",
        "    end                                                                                           ;\\\n",
        "    l/length(test)                                                                                ;\\\n",
        "end                                                                                               ;\\\n",
        "evalcb() = @show(test_loss())                                                                     ;\\\n",
        "epochs = 10                                                                                       ;\\\n",
        "@epochs epochs Flux.train!(loss, params(model), train, ADAM(0.005), cb=throttle(evalcb, 10))      ;\\\n",
        "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))                                           ;\\\n",
        "println( )                                                                                        ;\\\n",
        "println( \"accuracy :\" , accuracy(test_X, test_y) )                                                ;\\'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Info: Epoch 1\n",
            "test_loss() = 2.350677f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 2\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 3\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 4\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 5\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 6\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 7\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 8\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 9\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "[ Info: Epoch 10\n",
            "test_loss() = 2.3023286f0\n",
            "test_loss() = 2.3023286f0\n",
            "\n",
            "accuracy :0.15938076213890595\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}